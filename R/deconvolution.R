#' Log-likelihood for deconvoluting host and tumour read counts
#' @param PHa = parameter probability read is Host given read is A (P(H|A))
#' @param PHb = parameter probability read is Host given read is B (P(H|B))
#' @param n = normal read count in tumour
#' @param v = variant read count in tumour
#' @param logr = log ratio of tumour depth to host depth
#' @param pur = tumour purity
#' @param a = Expected number of host reads
#' @param b = Expected number of tumour reads
#' Log-likelihood for deconvoluting host and tumour read counts
#' @param PHa = parameter probability read is Host given read is A (P(H|A))
#' @param PHb = parameter probability read is Host given read is B (P(H|B))
#' @param n = normal read count in tumour
#' @param v = variant read count in tumour
#' @param r = ratio of tumour depth to host depth (Note: NOT logR)
#' @param pur = tumour purity
#' @param a = Expected number of host reads
#' @param b = Expected number of tumour reads
#' @examples
#' loglik(0.46, 0.42, 90, 15, exp(0.03670243), 0.59, 71, 8)
#' # [1] 3.356328
loglik <- function(PHa, PHb, n, v, r, pur, a, b) {
    estimated_num_host_a <- PHa * n
    estimated_num_host_b <- PHb * v
    estimated_num_host <- estimated_num_host_a + estimated_num_host_b
    observed_total_reads <- n + v

    # Expected number of tumour reads
    expected_num_tumour <- r * pur * (observed_total_reads - 1) / (r * pur + 1 - pur)

    # Expected number of host reads
    expected_num_host <- (1-pur) * (observed_total_reads - 1) / (r * pur + 1 - pur)

    # Likelihood
    P_read_is_tumour <- (observed_total_reads - estimated_num_host) / observed_total_reads
    P_host_read_is_a <- estimated_num_host_a / estimated_num_host

    ll <-
        (expected_num_tumour - 1) * log(P_read_is_tumour) +
        (expected_num_host - 1) * log(1-P_read_is_tumour) - lbeta(expected_num_tumour, expected_num_host) +
        (a - 1) * log(P_host_read_is_a) +
        (b - 1) * log(1-P_host_read_is_a) - lbeta(a, b)

    return (ll)
}

#' Gradient of log-likelihood for deconvoluting host and tumour read counts w.r.t PHa and PHb
#' @param PHa = parameter probability read is Host given read is A (P(H|A))
#' @param PHb = parameter probability read is Host given read is B (P(H|B))
#' @param n = normal read count in tumour
#' @param v = variant read count in tumour
#' @param r = ratio of tumour depth to host depth (Note: NOT logR)
#' @param pur = tumour purity
#' @param a = Expected number of host reads
#' @param b = Expected number of tumour reads
#' @examples
#' dloglik(0.46, 0.42, 90, 15, exp(0.03670243), 0.59, 71, 8)
#' # [1] -12.53092 -10.78414
dloglik <- function(PHa, PHb, n, v, r, pur, a, b) {
    # Expected total number of tumour reads
    ETt <- ((n + v - 1) * r * pur) / (r * pur + 1 - pur)

    # Expected number of host reads
    EHt <- (1-pur) * (n + v - 1) / (r * pur + 1 - pur)

    # Expected number of host A reads
    EHa <- PHa*n

    # Expected number of host B reads
    EHb <- PHb*v

    # Define terms used repeatedly to save multiplications
    EHa_sq <- EHa*EHa
    EHb_sq <- EHb*EHb
    EHa_EHb <- EHa*EHb
    denom_term <- (EHa_sq + 2*EHa_EHb - EHa*n - EHa*v + EHb_sq - EHb*n - EHb*v)

    # These expressions were generated by Sympy, so are fairly opaque (but they are correct)
    dPHa <- (EHt*EHa_EHb + EHt*EHa_sq - EHt*EHa*v - EHt*EHa*n + ETt*EHa_EHb + ETt*EHa_sq - EHa_sq*b - EHa_sq + EHa_EHb*a - EHa_EHb*b - 2*EHa_EHb + EHa*b*n + EHa*b*v + EHb_sq*a - EHb_sq - EHb*a*n - EHb*a*v + EHb*n + EHb*v)/(PHa*denom_term)
    dPHb <- (EHt*EHa_EHb + EHt*EHb_sq - EHt*EHb*n - EHt*EHb*v + ETt*EHa_EHb + ETt*EHb_sq + EHa_sq*b - EHa_sq - EHa_EHb*a + EHa_EHb*b - 2*EHa_EHb - EHa*b*n - EHa*b*v - EHb_sq*a - EHb_sq + EHb*a*n + EHb*a*v + EHa*v + EHa*n)/(PHb*denom_term)
    c(dPHa, dPHb)
}

#' Construct a matrix of read counts given the marginal REF and ALT totals,
#' and the conditional probabilities that a read came from the host, given its
#' status as an A (ref) or a B (alt) read
#' Table:
#'
#'     |   T   |   H    | total
#'  ---|-------|--------|------
#'   A |   .   | p(H|A) |  REF
#'   B |   .   | p(H|B) |  ALT
#'  ---|-------|--------|------
#'     |Σ(.|T) | Σ(.|H) |REF+ALT
#'
#' @param ref = Integer count of REF reads observed in (contaminated) tumour sample
#' @param alt = Integer count of ALT reads observed in tumour sample
#' @param p = Vector of conditional probabilities [p(H|A), p(H|B)]
count_matrix <- function(ref, alt, p) {
    m <- matrix(0, nrow = 3, ncol = 3)
    m[,3] <- c(ref, alt, ref+alt)
    m[1,2] <- p[1] * ref
    m[2,2] <- p[2] * alt
    m[1,1] <- ref - m[1,2]
    m[2,1] <- alt - m[2,2]
    m[3,1] <- sum(m[1:2,1])
    m[3,2] <- sum(m[1:2,2])
    m
}


#' Helper function to find the maximum likelihood estimate of P(H|A) and P(H|B)
find_mle <- function(tumour_ref, tumour_alt, host_ref, host_alt, logr, purity, hess = FALSE) {
    pseudocount <- 0.5
    n <- tumour_ref + pseudocount
    v <- tumour_alt + pseudocount
    a <- host_ref + pseudocount
    b <- host_alt + pseudocount
    r <- exp(logr)

    objective <- function(x) {
        -loglik(x[1], x[2], n, v, r, purity, a, b)
    }

    gradient <- function(x) {
        -dloglik(x[1], x[2], n, v, r, purity, a, b)
    }

    optim(c(0.5, 0.5), objective, gr = gradient, method = "L-BFGS-B",
          lower = c(1e-6, 1e-6),
          upper = c(1 - 1e-6, 1 - 1e-6),
          hessian = hess)
}

#' Helper function to find the maximum likelihood estimate of P(H|A) and P(H|B)
rcpp_module_find_mle <- function(tumour_ref, tumour_alt, host_ref, host_alt, logr, purity, hess = FALSE) {
    pseudocount <- 0.5
    n <- tumour_ref + pseudocount
    v <- tumour_alt + pseudocount
    a <- host_ref + pseudocount
    b <- host_alt + pseudocount
    r <- exp(logr)

    l <- new(Likelihood, n, v, r, purity, a, b)

    objective <- function(x) {
        -l$loglik(x[1], x[2])
    }

    gradient <- function(x) {
        -l$dloglik(x[1], x[2])
    }

    optim(c(0.5, 0.5), objective, gr = gradient, method = "L-BFGS-B",
          lower = c(1e-6, 1e-6),
          upper = c(1 - 1e-6, 1 - 1e-6),
          hessian = hess)
}

#' Helper function to find the maximum likelihood estimate of P(H|A) and P(H|B)
rcpp_find_mle <- function(tumour_ref, tumour_alt, host_ref, host_alt, logr, purity, hess = FALSE) {
    pseudocount <- 0.5
    n <- tumour_ref + pseudocount
    v <- tumour_alt + pseudocount
    a <- host_ref + pseudocount
    b <- host_alt + pseudocount
    r <- exp(logr)

    objective <- function(x) {
        -rcpp_loglik(x[1], x[2], n, v, r, purity, a, b)
    }

    gradient <- function(x) {
        -rcpp_dloglik(x[1], x[2], n, v, r, purity, a, b)
    }

    optim(c(0.5, 0.5), objective, gr = gradient, method = "L-BFGS-B",
          lower = c(1e-6, 1e-6),
          upper = c(1 - 1e-6, 1 - 1e-6),
          hessian = hess)
}
#' Estimate the host and tumour components from a host-contaminated tumour sample
#' @param tumour_ref number of REF reads observed in host-contaminated tumour, at current site
#' @param tumour_alt number of ALT reads observed in host-contaminated tumour, at current site
#' @param host_ref number of REF reads observed in matched host, at current site
#' @param host_alt number of ALT reads observed in matched host, at current site
#' @param logr log of ratio between tumour coverage and matched host coverage, at current site
#' @param purity Estimate of tumour purity (aka aberrant cell count)
#' @param plot Should a plot be drawn?
#' @importFrom "mixtools" ellipse
#' @return A list with the following elements:
#' * par = optimised parameters (\eqn{p(H | A)}, \eqn{p(H | B)})
#' * cov = estimated covariance of optimised parameters
#'       (Fisher information - inverse of Hessian)
#' * counts = Matrix of inferred read counts, divided by Host/Tumour, A/B-allele
#' * pure_tumour_vaf = Estimate of tumour VAF in absence of host
#' * pure_host_vaf = Estimate of host VAF in absence of tumour
#' * sample_vaf_with_het_host = An estimate of what the sample VAF would be if the host were exactly
#'   heterozygous
#' @md
#' @examples
#' deconvolute(90, 15, 71, 8, 0.03670243, 0.59, FALSE)
#' @export
deconvolute <- function(tumour_ref, tumour_alt, host_ref, host_alt, logr, purity, plot=FALSE) {
    # All the numerical work is done in find_mle. the rest of this function
    # is for convenient presentation of the result.
    result <- find_mle(tumour_ref, tumour_alt, host_ref, host_alt, logr, purity, hess = TRUE)

    covariance <- solve(result$hessian)
    counts <- count_matrix(tumour_ref, tumour_alt, result$par)

    if (plot) {
        # Compute objective over a grid
        X <- seq(0.01, 0.99, length.out = 99)
        Y <- seq(0.01, 0.99, length.out = 99)
        g <- expand.grid(X, Y)
        z <- apply(g, 1, objective)
        g$z <- z

        # Maps objective values to colours: optimum=red
        colours <- colorRamp(c("red","white", "blue"), bias=5, space = "rgb")((z - min(z)) / (max(z - min(z))))
        colours <- apply(colours, 1, function(x) do.call(rgb, as.list(x/255)))

        layout(matrix(c(1,1,1,2), nrow=1))
        plot(g[,1], g[,2], pch = 15, col = colours, asp = TRUE,
             ylab = "P(source=Host|read=Ref)", xlab = "P(source=H|read=Alt)",
             main = "Deconvolution result", cex=2,
             xlim = c(0,1), ylim = c(0,1))
        points(result$par[1], result$par[2], pch = 4, cex = 5, lwd=2)

        # Can use points in `ell` to construct CI around tumour and host vaf estimates
        ell<-ellipse(result$par, abs(covariance), newplot = FALSE, lty=1, lwd=2, npoints=100)
        mats <- apply(ell, 1, count_matrix, ref=tumour_ref, alt=tumour_alt)
        tvafs <- apply(mats, 2, function(x) x[2] / x[3])
        hvafs <- apply(mats, 2, function(x) x[5] / x[6])
        hvafs_min <- which.min(hvafs)
        hvafs_max <- which.max(hvafs)
        tvafs_min <- which.min(tvafs)
        tvafs_max <- which.max(tvafs)

        points(ell[hvafs_min, 1], ell[hvafs_min, 2], pch = 1, col = "goldenrod")
        points(ell[hvafs_max, 1], ell[hvafs_max, 2], pch = 4, col = "goldenrod")
        points(ell[tvafs_min, 1], ell[tvafs_min, 2], pch = 1, col = "dodgerblue")
        points(ell[tvafs_max, 1], ell[tvafs_max, 2], pch = 4, col = "dodgerblue")

        orig_vaf <- tumour_alt / (tumour_alt+tumour_ref)
        xs <- 1:3
        ys <- c(tumour_alt / (tumour_alt+tumour_ref), counts[2,1]/counts[3,1], counts[2,2]/counts[3,2])
        error_bars <- matrix(c(qbeta(0.025, tumour_alt, tumour_ref), qbeta(0.975, tumour_alt, tumour_ref),
                               tvafs[tvafs_min], tvafs[tvafs_max],
                               hvafs[hvafs_min], hvafs[hvafs_max]), nrow = 2, ncol = 3)
        plot(xs, ys, main = "VAF estimates", xlab=NA, ylab = "VAF", xaxt='n', type = "n", xlim = c(0.75, 3.25), ylim=c(0,1))#range(error_bars) * c(1/1.1, 1.1))
        rect(0.975, error_bars[1,1], 1.025, error_bars[2,1], col = "seagreen", border=NA)
        rect(1.975, error_bars[1,2], 2.025, error_bars[2,2], col = "dodgerblue", border = NA)
        rect(2.975, error_bars[1,3], 3.025, error_bars[2,3], col = "goldenrod", border = NA)
        abline(h=ys, col = c("seagreen", "dodgerblue", "goldenrod"), lty=3, lwd=0.5)
        points(xs, ys, pch = 21, cex = 2, bg = c("seagreen", "dodgerblue", "goldenrod"), lwd = 2)
        axis(1, at=1:3, labels = c("Original", "Pure tumour", "Pure host"))
    }

    list(par=result$par, cov=covariance, counts=counts,
         pure_tumour_vaf=counts[2,1] / counts[3,1],
         pure_host_vaf=counts[2,2] / counts[3,2],
         sample_vaf_with_het_host=(counts[2,1] + counts[3,2] / 2) / counts[3,3])
}

#' Uses \code{deconvolute} to calculate adjusted tumour vaf as it would be if all host contamination were heterozygous
convert_to_het_host <- function(tumour_ref, tumour_alt, host_ref, host_alt, logr, purity) {
    deconvolute(tumour_ref, tumour_alt, host_ref, host_alt, logr, purity, plot = FALSE)$sample_vaf_with_het_host
}

#' Uses \code{deconvolute} to calculate adjusted tumour vaf as it would be if there were no host contamination
estimate_tumour_vaf <- function(tumour_ref, tumour_alt, host_ref, host_alt, logr, purity) {
    deconvolute(tumour_ref, tumour_alt, host_ref, host_alt, logr, purity, plot = FALSE)$pure_tumour_vaf
}

#' Uses \code{deconvolute} to calculate adjusted tumour vaf as it would be if there were no host contamination
#' (vectorised over indicated parameters)
#' @param tumour_ref (vectorised) - number of REF reads observed in host-contaminated tumour, at current site
#' @param tumour_alt (vectorised) - number of ALT reads observed in host-contaminated tumour, at current site
#' @param host_ref (vectorised) - number of REF reads observed in matched host, at current site
#' @param host_alt (vectorised) - number of ALT reads observed in matched host, at current site
#' @param logr (vectorised) - log of ratio between tumour coverage and matched host coverage, at current site
#' @param purity (NOT vectorised) - Estimate of tumour purity (aka aberrant cell count)
#' @return vector of VAF values
#' @export
v.estimate_tumour_vaf <-
    Vectorize(estimate_tumour_vaf,
              vectorize.args = c("tumour_ref", "tumour_alt", "host_ref", "host_alt", "logr"))

#' Uses \code{deconvolute} to calculate adjusted tumour vaf as it would be if all host contamination were heterozygous
#' (vectorised over indicated parameters)
#' @param tumour_ref (vectorised) - number of REF reads observed in host-contaminated tumour, at current site
#' @param tumour_alt (vectorised) - number of ALT reads observed in host-contaminated tumour, at current site
#' @param host_ref (vectorised) - number of REF reads observed in matched host, at current site
#' @param host_alt (vectorised) - number of ALT reads observed in matched host, at current site
#' @param logr (vectorised) - log of ratio between tumour coverage and matched host coverage, at current site
#' @param purity (NOT vectorised) - Estimate of tumour purity (aka aberrant cell count)
#' @return vector of VAF values
#' @export
v.convert_to_het_host <-
    Vectorize(convert_to_het_host,
              vectorize.args = c("tumour_ref", "tumour_alt", "host_ref", "host_alt", "logr"))


#######
# WIP functions not for export yet - 24/04/2019

get_counts <-
    function(tumour_ref, tumour_alt, host_ref, host_alt, logr, purity) deconvolute(tumour_ref, tumour_alt, host_ref, host_alt, logr, purity, FALSE)$counts

.v.get_counts <-
    Vectorize(get_counts, vectorize.args = c("tumour_ref", "tumour_alt", "host_ref", "host_alt", "logr"))

v.get_counts <- function(tumour_ref, tumour_alt, host_ref, host_alt, logr, purity) {
    arr <- .v.get_counts(tumour_ref, tumour_alt, host_ref, host_alt, logr, purity)
    array(arr, dim = c(3, 3, length(tumour_ref)))
}


.get_sequence <-
    function(refbase, altbase, tumour_ref, tumour_alt, host_ref, host_alt, logr, purity, minreads, minvaf)
    {
        if (tumour_ref + tumour_alt == 0) {
            return ("N")
        }
        result <- deconvolute(tumour_ref, tumour_alt, host_ref, host_alt, logr, purity, FALSE)$counts[2:3, 1]
        ifelse(result[1] >= minreads & result[1]/result[2] >= minvaf, altbase, refbase)
    }

.v.get_sequence <-
    Vectorize(.get_sequence, vectorize.args = c("refbase", "altbase", "tumour_ref", "tumour_alt", "host_ref", "host_alt", "logr"))

v.get_sequence <- function(refbase, altbase, tumour_ref, tumour_alt, host_ref, host_alt, logr, purity, minreads, minvaf) {
    paste(.v.get_sequence(refbase, altbase, tumour_ref, tumour_alt, host_ref, host_alt, logr, purity, minreads, minvaf), collapse = "")
}



### Fast alternatives


# Refactor...
#' Fast deconvolution of read count contingency table
#' @param total_readdepth Tumour sample total read depth
#' @param alt_readdepth Tumour sample alt read depth
#' @param logr Tumour sample logR
#' @param hvaf Host sample VAF
#' @param purity Estimated purity of tumour sample
.estimate_contingency_table <- function(total_readdepth, alt_readdepth, logr, hvaf, purity) {
    # Aim: find values for the empty cells (a), (b), (c), (d), (e), (f)
    # in the read count contingency table below. A and T are observed values, and R = T - A.
    # The other values need to be estimated, subject to the constraint that they are all
    # non-negative.
    # (c) (referred to throughout as variable K) can be estimated as T*p_1, where p_1 is the
    # probability that a read came from host material in the mixed tumour-host source. p_1
    # is estimated using the tumour sample's logR (logr), and the host sample's VAF (hvaf).
    # (b) (variable L) is estimated from (c) as K*p_2, where p_2 is the probability that
    # a host-derived read carries the Alt allele, not the Ref allele. p_2 is equal to hvaf.
    # As the table has 2 degrees of freedom, once values are estimated for (b) and (c), the
    # other missing values are filled in trivially.

    # Contingency table :
    #'         |  Ref  |  Alt  |
    #'  -------|-------|-------|-------
    #'   Host  |  (a)  |  (b)  |  (c)
    #'  Tumour |  (d)  |  (e)  |  (f)
    #'  -------|-------|-------|-------
    #'         |   R   |   A   |   T

    r <- 2^logr
    T <- total_readdepth
    A <- alt_readdepth

    # probability that a read comes from the host (P(R=H))
    p_1 <- (1 - purity) / (r * purity + 1 - purity)

    # probability that a host read is an Alt allele (P(R=A|R=H))
    p_2 <- hvaf

    # Estimate K (number of host reads) and L (number of host reads that are Alt),
    # subject to the constraints A - L >= 0, and (T - K) - (A - L) >= 0

    K <- T*p_1
    L <- K*p_2

    # If constraints are broken, then find the optimal least squares solution to the
    # constrained equation, using Lagrangian multipliers.
    # Least-squares estimate for K and L:
    # f(K, L) = (K - T*p_1)^2 + (L - K*p_2)
    #
    # Constraints:
    # g1(L, a) => A - L - a^2 = 0
    # g2(K, L, b) => (T-K) - (A-L) - b^2 = 0
    #
    # Augmented Lagrangian equation:
    # F(K, L, a, b, λ1, λ2) = f(K, L) + λ1*g1(L, a) + λ2*g2(K, L, b)
    #
    # Optimal constrained solution obtained when all derivatives of F are zero.

    # Broken constraint 1: Too many Alt reads in the host
    ix <- (L > A)

    K[ix] <- (A[ix]*p_2[ix] + T[ix]*p_1[ix]) / (p_2[ix]^2 + 1)
    L[ix] <- A[ix]

    # Broken constraint 2: VAF out of bounds [ignore if T==0 - these will give NA in the index, which breaks]
    iy <- (T > 0) & (((A-L) / (T-K)) > 1)
    denom <- (p_2[iy]^2 - 2 * p_2[iy] + 2)
    K[iy] <- (A[iy] * (p_2[iy] - 1) + T[iy] * (p_1[iy] - p_2[iy] + 1)) / denom
    L[iy] <- (A[iy] * (p_2[iy]^2 - p_2[iy] + 1) + T[iy] * (p_1[iy] - p_2[iy]^2 + p_2[iy] - 1) ) / denom

    # Contingency table :
    #'     |  Ref  |  Alt  |
    #'  ---|-------|-------|-------
    #'   H |  K-L  |   L   |   K
    #'   T |T-K-A+L|  A-L  |  T-K
    #'  ---|-------|-------|-------
    #'     |   R   |   A   |   T

    return(list(K=K, L=L))
}

#' Fast approximate estimate of pure_tumour_vaf from a mixed sample
#' @param total_readdepth Tumour sample total read depth
#' @param alt_readdepth Tumour sample alt read depth
#' @param logr Tumour sample logR
#' @param hvaf Host sample VAF
#' @param purity Estimated purity of tumour sample
#' @export
fast_estimate_tumour_vaf <- function(total_readdepth, alt_readdepth, logr, hvaf, purity) {
    result <- .estimate_contingency_table(total_readdepth, alt_readdepth, logr, hvaf, purity)
    T <- total_readdepth
    A <- alt_readdepth
    vaf <- (A-result$L) / (T-result$K)
    return (vaf)
}

#' Fast approximate estimate of pure_tumour_vaf from a mixed sample
#' @param total_readdepth Tumour sample total read depth
#' @param alt_readdepth Tumour sample alt read depth
#' @param logr Tumour sample logR
#' @param hvaf Host sample VAF
#' @param purity Estimated purity of tumour sample
#' @param pseudocount Avoid infinite log-odds by adding a pseudocount to each
#'     cell of the contingency table. Default = 0.5 (same as Facets).
#' @export
fast_estimate_tumour_logodds <- function(total_readdepth, alt_readdepth, logr, hvaf, purity, pseudocount=0.5) {
    result <- .estimate_contingency_table(total_readdepth, alt_readdepth, logr, hvaf, purity)
    T <- total_readdepth
    A <- alt_readdepth
    L <- result$L
    K <- result$K
    odds <- ((T-K-A+L+pseudocount)*(L+pseudocount)) / ((K-L+pseudocount) * (A-L+pseudocount))
    return (log(odds))
}

#' Fast approximate estimate of pure_tumour_vaf from a mixed sample
#' @param total_readdepth Tumour sample total read depth
#' @param alt_readdepth Tumour sample alt read depth
#' @param logr Tumour sample logR
#' @param hvaf Host sample VAF
#' @param purity Estimated purity of tumour sample
#' @param pseudocount Avoid infinite log-odds by adding a pseudocount to each
#'     cell of the contingency table. Default = 0.5 (same as Facets).
#' @export
fast_estimate_contingency_table <- function(total_readdepth, alt_readdepth, logr, hvaf, purity, pseudocount=0.5) {
    result <- .estimate_contingency_table(total_readdepth, alt_readdepth, logr, hvaf, purity)
    T <- total_readdepth
    A <- alt_readdepth
    L <- result$L
    K <- result$K
    return (list(a=K-L, b=L, c=K, d=T-K-A+L, e=A-L, f=T-K, g=T-A, h=A, i=T))
}

